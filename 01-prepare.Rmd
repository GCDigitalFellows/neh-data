---
title: "Prepare data"
---

### Downloading source files

Fortunately, the NEH provides open access to their [grants data](https://securegrants.neh.gov/open/data/). We first use `rvest::read_html` to get a list of all the zipped grant files:

```{r}
listnehgrantzips <- function() {
  indexurl <- 'https://securegrants.neh.gov/open/data'
  zipurls <- read_html(indexurl) %>%
    html_nodes('a[href*="NEH_Grants"][href$=".zip"]') %>%
    html_attr('href') %>%
    paste0(indexurl, .)
}
```

Each grant zip file contains an XML data file and an XML Schema Definition file, which we can ignore for our current purposes. We save the XML to a directory in our project directory:

```{r}
downloadxml <- function(url) {
  DATADIR <- './.data'
  # intermediate files will be saved between steps
  dir.create(DATADIR, showWarnings = FALSE)
  xmlfile <- gsub(".zip", ".xml", basename(url))
  # only download if xml file doesn't already exist
  if(!file.exists(file.path(DATADIR, xmlfile))) {
    tf <- tempfile()
    download.file(url, tf, quiet = TRUE)
    unzip(tf, xmlfile, exdir=DATADIR)
  } else {
    file.path(DATADIR, xmlfile)
  }
}
```

Finally, we pull these two functions together using `purrr::map` to download each file:

```{r}
xmlfiles <- listnehgrantzips() %>% map(~ downloadxml(.)) %>% unlist
```

### Extracting data from source files

The XML format can be difficult to load into a data table for analysis. It requires us to transform its nested structure into a unnested table form, with rows and columns. We use the `xml2::read_xml` function to pull nodes out of the XML tree structure:

```{r}
read_xml(tail(xmlfiles, 1)) %>% 
  xml_find_all('./Grant') %>%
  head(1) %>%
  xml_children()
```

We need to pull out the `AppNumber` attribute since this is the unique number used by the NEH to identify awarded grants.

Of the 28 fields that are in the nodeset for each Grant, `Participant` and `Discipline` are nested nodes. The `Discipline` node is simply a list of `Name` nodes.

```{r}
read_xml('.data/NEH_Grants2000s.xml') %>% 
  xml_find_all('./Grant/*[count(*) > 0]') %>%
  head(5)
```

Following [How to tame XML with nested data frames and purrr](https://github.com/jennybc/manipulate-xml-with-purrr-dplyr-tidyr#readme), we create the following function to transform our XML data to a data frame:

```{r}
xmltodf <- function(xmlfile) {
  grants <- read_xml(xmlfile) %>% xml_find_all('./Grant')
  df <- data_frame(row = seq_along(grants),
                   nodeset = grants) %>%
    mutate(col_name_raw = nodeset %>% map(~ xml_children(.)) %>% map(~ xml_name(.)),
           cell_text = nodeset %>% map(~ xml_children(.)) %>% map(~ xml_text(.)),
           appnumber = nodeset %>% xml_attr('AppNumber'),
           i = nodeset %>% map(~ xml_children(.)) %>% map(~ seq_along(.))) %>%
    select(row, i, appnumber, col_name_raw, cell_text) %>%
    unnest() %>%
    group_by(row, appnumber, col_name_raw) %>% 
    summarise(cell_text = toString(cell_text)) %>%
    ungroup() %>%
    spread(col_name_raw, cell_text)
  df
}
```

We use the `xmltodf` function to through all the XML files we have downloaded and transform them into data frames that we finally combine into one, which we save to the file system to avoid redoing the same steps as we continue our exploration of the data:

```{r}
preparedata <- function() {
  GRANTSFILEPATH <- '.data/grants.rda'
  if(!file.exists(GRANTSFILEPATH)) {
    grants <- xmlfiles %>% 
      map(~ xmltodf(.)) %>%
      bind_rows() %>%
      mutate_if(is.character, funs(type.convert)) %>%
      mutate_if(is.list, as.character) %>%
      select(-ProjectDesc, -ToSupport) %>% # FIXME: These fields are causing duplicates
      distinct()
    save(grants, file=GRANTSFILEPATH)
  }
  load(GRANTSFILEPATH)
}
preparedata()
```